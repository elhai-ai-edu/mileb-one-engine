// functions/chat.js â€” MilEd.One v4.4
// Dynamic config + Model routing + Kernel injection + Guards + Enhanced research logging

const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY;
const OPENROUTER_URL     = "https://openrouter.ai/api/v1/chat/completions";
const SITE_URL           = "https://cozy-seahorse-7c5204.netlify.app";

// â”€â”€ × ×™×ª×•×‘ ××•×“×œ×™× â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const MODEL_THINKING = "google/gemini-2.0-flash-thinking-exp";
const MODEL_FAST     = "google/gemini-2.0-flash-001";

const THINKING_BOT_TYPES = [
  "faculty_assistant",
  "faculty_bot_builder",
  "faculty_support",
  "faculty_lesson_builder",
  "task_final_project",
  "skills_diagnostic",
  "skills_career_diagnostic",
  "admin_analytics"
];

function selectModel(botType) {
  if (botType && THINKING_BOT_TYPES.includes(botType))
    return MODEL_THINKING;
  return MODEL_FAST;
}

// â”€â”€ Cache ×©×œ config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
let cachedConfig = null;

async function loadConfig() {
  if (cachedConfig) return cachedConfig;
  try {
    const res = await fetch(`${SITE_URL}/config.json`);
    if (!res.ok) return null;
    cachedConfig = await res.json();
    return cachedConfig;
  } catch (e) {
    console.error('config error:', e.message);
    return null;
  }
}

// â”€â”€ ×—×™×¤×•×© ×‘×•×˜ ×œ×¤×™ botType â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function findBot(config, botType) {
  if (!config || !botType) return null;

  for (let id in config.universal?.items || {}) {
    if (config.universal.items[id].botType === botType)
      return config.universal.items[id];
  }

  for (let branch in config.branches || {}) {
    for (let id in config.branches[branch]?.items || {}) {
      if (config.branches[branch].items[id].botType === botType)
        return config.branches[branch].items[id];
    }
  }

  return null;
}

// â”€â”€ × ×™×ª×•×— ×©××œ×” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function analyzeMessage(message) {
  const isQuestion = message.includes('?') || message.includes('××”') ||
                     message.includes('××™×š') || message.includes('×œ××”') ||
                     message.includes('××ª×™') || message.includes('××™×¤×”');
  const wordCount = message.trim().split(/\s+/).length;
  return { isQuestion, wordCount };
}

// â”€â”€ Kernel Guards â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function detectFullSolutionRequest(message) {
  const lower = message.toLowerCase();
  return (
    lower.includes("×ª×¤×ª×•×¨ ×œ×™") ||
    lower.includes("×ª×›×ª×•×‘ ×œ×™ ××ª ×”×¢×‘×•×“×”") ||
    lower.includes("×ª×¢× ×” ×‘××§×•××™") ||
    lower.includes("solve for me") ||
    lower.includes("write it for me")
  );
}

function looksLikeFullAnswer(reply) {
  return reply.length > 1200; // heuristic ×¨××©×•× ×™
}

const DEFAULT_PROMPT = "××ª×” ×¢×•×–×¨ ×œ×™××•×“×™ ×¡×•×§×¨×˜×™ ×•×—×. ×¢× ×” ×‘×¢×‘×¨×™×ª ×•×©××œ ×©××œ×•×ª ×‘××§×•× ×œ×ª×ª ×ª×©×•×‘×•×ª ×™×©×™×¨×•×ª.";

// â”€â”€ ×¤×•× ×§×¦×™×” ×¨××©×™×ª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
exports.handler = async (event) => {
  const headers = {
    "Access-Control-Allow-Origin":  "*",
    "Access-Control-Allow-Headers": "Content-Type",
    "Content-Type": "application/json"
  };

  if (event.httpMethod === "OPTIONS") return { statusCode: 200, headers, body: "" };
  if (event.httpMethod !== "POST")    return { statusCode: 405, headers, body: JSON.stringify({ error: "Method not allowed" }) };

  try {
    const {
      message   = "×©×œ×•×",
      history   = [],
      botType   = null,
      studentId = "anonymous",
      classId   = null
    } = JSON.parse(event.body || "{}");

    const model      = selectModel(botType);
    const config     = await loadConfig();
    const botConfig  = findBot(config, botType);
    const logContent = config?.engine?.logContent ?? false;
    const systemPrompt = botConfig?.systemPrompt || DEFAULT_PROMPT;

    // â”€â”€ Kernel Injection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const kernel = config?.engine?.kernel || {};

    let kernelBlock = "";

    if (kernel.preserveAgency)
      kernelBlock += "×©××•×¨ ×¢×œ ×¡×•×›× ×•×ª ×”×œ×•××“. ";

    if (kernel.noFullSolutionForStudent)
      kernelBlock += "××œ ×ª×¤×ª×•×¨ ××©×™××•×ª ×‘××œ×•××Ÿ ×¢×‘×•×¨ ×¡×˜×•×“× ×˜. ";

    if (kernel.noSkipStructuralSteps)
      kernelBlock += "××œ ×ª×“×œ×’ ×¢×œ ×©×œ×‘×™× ××‘× ×™×™× ×‘×ª×”×œ×™×š ×—×©×™×‘×”. ";

    if (kernel.evaluationRequiresExplicitCriteria)
      kernelBlock += "××™×Ÿ ×œ×‘×¦×¢ ×”×¢×¨×›×” ×œ×œ× ×§×¨×™×˜×¨×™×•× ×™× ××¤×•×¨×©×™× ×•×××•×©×¨×™×. ";

    if (kernel.preventRoleMutation)
      kernelBlock += "××™×Ÿ ×œ×©× ×•×ª ×ª×¤×§×™×“ ×‘××”×œ×š ×”×©×™×—×”. ";

    if (kernel.invisibleEffortRegulation)
      kernelBlock += "×•×™×¡×•×ª ××××¥ ×¦×¨×™×š ×œ×”×™×•×ª ××“×•×¨×’ ×•××™× ×• ×’×œ×•×™ ×œ××©×ª××©. ";

    const finalSystemPrompt = kernelBlock
      ? kernelBlock + "\n\n" + systemPrompt
      : systemPrompt;

    // â”€â”€ ×”×’×‘×œ×ª ×”×™×¡×˜×•×¨×™×” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const trimmedHistory = history.slice(-14);

    // â”€â”€ Role Mutation Guard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if (kernel.preventRoleMutation) {
      trimmedHistory.forEach(m => {
        if (m.role === "system") {
          m.role = "assistant";
        }
      });
    }

    // â”€â”€ Kernel Pre-Guard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if (kernel.noFullSolutionForStudent && detectFullSolutionRequest(message)) {
      return {
        statusCode: 200,
        headers,
        body: JSON.stringify({
          reply: "×× ×™ ×›××Ÿ ×›×“×™ ×œ×¢×–×•×¨ ×œ×š ×œ×—×©×•×‘ ×•×œ×‘× ×•×ª ××ª ×”×ª×©×•×‘×” ×‘×¢×¦××š ğŸ™‚ ×‘×•× × ×ª×—×™×œ ×‘×¦×¢×“ ×”×¨××©×•×Ÿ ×™×—×“ â€” ××” ×›×‘×¨ ×™×© ×œ×š?",
          botType,
          botName: botConfig?.name || null,
          model: "kernel-guard",
          isThinking: false
        })
      };
    }

    const messages = [
      { role: "system", content: finalSystemPrompt },
      ...trimmedHistory.map(m => ({
        role: m.role === "assistant" ? "assistant" : "user",
        content: m.content
      })),
      { role: "user", content: message }
    ];

    // â”€â”€ ×§×¨×™××” ×œ-OpenRouter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const response = await fetch(OPENROUTER_URL, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${OPENROUTER_API_KEY}`,
        "Content-Type":  "application/json",
        "HTTP-Referer":  SITE_URL,
        "X-Title":       "MilEd.One"
      },
      body: JSON.stringify({ model, messages, max_tokens: 1024, temperature: 0.7 })
    });

    const data  = await response.json();
    const reply = data.choices?.[0]?.message?.content || JSON.stringify(data);

    // â”€â”€ Kernel Post-Guard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if (kernel.noFullSolutionForStudent && looksLikeFullAnswer(reply)) {
      console.warn("Kernel detected possible full solution.");
    }

    // â”€â”€ × ×™×ª×•×— ×”×•×“×¢×” ×œ××—×§×¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const { isQuestion, wordCount } = analyzeMessage(message);

    const logEntry = {
      timestamp: new Date().toISOString(),
      studentId,
      classId,
      botType,
      botName: botConfig?.name || "unknown",
      layer: botConfig?._layer || "unknown",
      model,
      isThinking: model === MODEL_THINKING,
      historyLength: trimmedHistory.length,
      sessionTurn: Math.floor(trimmedHistory.length / 2) + 1,
      messageWordCount: wordCount,
      messageIsQuestion: isQuestion,
      replyLength: reply.length,
      tokensUsed: data.usage || null
    };

    if (logContent) {
      logEntry.messageContent = message;
      logEntry.replyContent   = reply.slice(0, 200);
    }

    console.log("RESEARCH_LOG:", JSON.stringify(logEntry));

    return {
      statusCode: 200,
      headers,
      body: JSON.stringify({
        reply,
        botType,
        botName: botConfig?.name || null,
        model,
        isThinking: model === MODEL_THINKING
      })
    };

  } catch (err) {
    console.error("Error:", err);
    return { statusCode: 500, headers, body: JSON.stringify({ error: err.message }) };
  }
};
